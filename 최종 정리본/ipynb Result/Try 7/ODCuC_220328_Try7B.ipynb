{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ODCuC_220328_Try7B.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NewTAs/ODCuC/blob/main/ODCuC_220328_Try7B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgBO72ZY81tE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9247df86-37ad-49f9-c474-0cecf9a37268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at Lee_dataset\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('Lee_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numberOfClass = 2\n",
        "pictureWeightHeightSize = 224\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/Lee_dataset/MyDrive/CNNDATA/220328/Train/',\n",
        "        target_size=(pictureWeightHeightSize, pictureWeightHeightSize),\n",
        "        batch_size=numberOfClass,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/Lee_dataset/MyDrive/CNNDATA/220328/Test/',\n",
        "        target_size=(pictureWeightHeightSize, pictureWeightHeightSize),    \n",
        "        batch_size=numberOfClass,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "H9aasxuq-Pia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8bd974-3928-4612-a9b1-40d0f4e1e0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 500 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Recall and Declare Convolutional Neural Network Models.\n",
        "\n",
        "Using CNN Models: InceptionResNetV2, Xception, MobileNetV2, ResNet50, InceptionV3\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "metadata": {
        "id": "KNSNoHgjeMyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Learning four models using repetitive statements without interruption.\n",
        "\"\"\"\n",
        "for i in range(5):\n",
        "    if i == 0:\n",
        "        model = InceptionResNetV2(include_top=True, weights=None, input_shape=(224, 224, 3), pooling=max, classes=numberOfClass)\n",
        "    elif i == 1:\n",
        "        model = Xception(include_top=True, weights=None, input_shape=(224, 224, 3), pooling=max, classes=numberOfClass)\n",
        "    elif i == 2:\n",
        "        model = MobileNetV2(include_top=True, weights=None, input_shape=(224, 224, 3), pooling=max, classes=numberOfClass)\n",
        "    elif i == 3:\n",
        "        model = ResNet50(include_top=True, weights=None, input_shape=(224, 224, 3), pooling=max, classes=numberOfClass)\n",
        "    else:\n",
        "        model = InceptionV3(include_top=True, weights=None, input_shape=(224, 224, 3), pooling=max, classes=numberOfClass)\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "    model.fit(train_generator, epochs=100, validation_data = test_generator)\n",
        "        \n",
        "    score = model.evaluate(test_generator)[1] * 100\n",
        "    print(f'{i} -- Evaluate -- : {score:.2f}')\n",
        "    print(score)\n",
        "\n",
        "    if i == 0:\n",
        "      model.save(\"/content/Lee_dataset/MyDrive/CNNDATA/Result/7B_InceptionResNetV2_Model\")\n",
        "    elif i == 1:\n",
        "      model.save(\"/content/Lee_dataset/MyDrive/CNNDATA/Result/7B_Xception_Model\")\n",
        "    elif i == 2:\n",
        "      model.save(\"/content/Lee_dataset/MyDrive/CNNDATA/Result/7B_MobileNetV2_Model\")\n",
        "    elif i == 3:\n",
        "      model.save(\"/content/Lee_dataset/MyDrive/CNNDATA/Result/7B_ResNet50_Model\")\n",
        "    else:\n",
        "      model.save(\"/content/Lee_dataset/MyDrive/CNNDATA/Result/7B_InceptionV3_Model\")"
      ],
      "metadata": {
        "id": "eFApPT_d-q2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd3ae32-dcd0-4263-f9f0-8cd56707f0fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [==============================] - 15s 60ms/step - loss: 0.0600 - accuracy: 0.9820 - val_loss: 0.5680 - val_accuracy: 0.8700\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9100\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9100\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.1144 - accuracy: 0.9740 - val_loss: 0.5091 - val_accuracy: 0.8700\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.2968 - val_accuracy: 0.9000\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 15s 58ms/step - loss: 0.0221 - accuracy: 0.9940 - val_loss: 0.6413 - val_accuracy: 0.9000\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.6330 - val_accuracy: 0.8600\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.0077 - accuracy: 0.9960 - val_loss: 0.5055 - val_accuracy: 0.8600\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 15s 58ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.3896 - val_accuracy: 0.8700\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.0360 - accuracy: 0.9860 - val_loss: 0.6519 - val_accuracy: 0.8700\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.9200\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.9200\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.0133 - accuracy: 0.9940 - val_loss: 0.3957 - val_accuracy: 0.9000\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.0436 - accuracy: 0.9960 - val_loss: 0.7280 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 0.5781 - val_accuracy: 0.8700\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.9200\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.4115 - val_accuracy: 0.9400\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9200\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.3577 - val_accuracy: 0.9200\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 5.1844e-04 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9200\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.1349 - accuracy: 0.9660 - val_loss: 0.6787 - val_accuracy: 0.8200\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0577 - accuracy: 0.9820 - val_loss: 0.9167 - val_accuracy: 0.7900\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.6484 - val_accuracy: 0.8300\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5613 - val_accuracy: 0.8700\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.2248 - val_accuracy: 0.9100\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.4090 - val_accuracy: 0.9200\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 15s 62ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.9200\n",
            "50/50 [==============================] - 2s 32ms/step - loss: 0.4807 - accuracy: 0.9200\n",
            "4 -- Evaluate -- : 92.00\n",
            "92.00000166893005\n",
            "INFO:tensorflow:Assets written to: /content/Lee_dataset/MyDrive/CNNDATA/Result/7B_InceptionV3_Model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W2Vc9TgtyE9D"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}